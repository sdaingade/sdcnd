{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test\n",
    "\n",
    "Once you've picked out your best model, it's time to test it!\n",
    "\n",
    "    Try to get the highest validation accuracy possible. Feel free to use all the previous concepts and train for as many epochs as needed.\n",
    "    Select your best model and train it one more time.\n",
    "    Use the test data and the Keras evaluate() method to see how well the model does.\n",
    "\n",
    "Dropout\n",
    "\n",
    "    Build from the previous network.\n",
    "    Add a dropout layer after the pooling layer. Set the dropout rate to 50%.\n",
    "    Make sure to note from the documentation above that the rate specified for dropout in Keras is the opposite of TensorFlow! TensorFlow uses the probability to keep nodes, while Keras uses the probability to drop them.\n",
    "\n",
    "Pooling\n",
    "\n",
    "    Build from the previous network\n",
    "    Add a 2x2 max pooling layer immediately following your convolutional layer.\n",
    "    Train for 3 epochs again. You should be able to get over 50% training accuracy.\n",
    "\n",
    "Convolutions\n",
    "\n",
    "    Build from the previous network.\n",
    "    Add a convolutional layer with 32 filters, a 3x3 kernel, and valid padding before the flatten layer.\n",
    "    Add a ReLU activation after the convolutional layer.\n",
    "    Train for 3 epochs again, should be able to get over 50% accuracy.\n",
    "\n",
    "Hint: The Keras example of a convolutional neural network for MNIST would be a good example to review.\n",
    "\n",
    "In this quiz you will build a multi-layer feedforward neural network to classify traffic sign images using Keras.\n",
    "\n",
    "    Set the first layer to a Flatten() layer with the input_shape set to (32, 32, 3).\n",
    "    Set the second layer to a Dense() layer with an output width of 128.\n",
    "    Use a ReLU activation function after the second layer.\n",
    "    Set the output layer width to 5, because for this data set there are only 5 classes.\n",
    "    Use a softmax activation function after the output layer.\n",
    "    Train the model for 3 epochs. You should be able to get over 50% training accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load pickled data\n",
    "with open('small_train_traffic.p', mode='rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, y_train = data['features'], data['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Setup Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 30, 30, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 14400)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1843328   \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 1,845,765\n",
      "Trainable params: 1,845,765\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# TODO: Build the Final Test Neural Network in Keras Here\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), padding='valid', input_shape=(32,32,3)))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(5))\n",
    "\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess data\n",
    "X_normalized = np.array(X_train / 255.0 - 0.5 )\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_one_hot = label_binarizer.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/20\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 1.3792 - acc: 0.3000 - val_loss: 0.8426 - val_acc: 0.5500\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 1.0149 - acc: 0.5250 - val_loss: 0.5224 - val_acc: 0.8500\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.7259 - acc: 0.6375 - val_loss: 0.4282 - val_acc: 0.8500\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.7946 - acc: 0.7000 - val_loss: 0.3983 - val_acc: 0.7500\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.4848 - acc: 0.7375 - val_loss: 0.3156 - val_acc: 0.8500\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.4989 - acc: 0.7750 - val_loss: 0.2807 - val_acc: 0.8500\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.5238 - acc: 0.7750 - val_loss: 0.2181 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.4574 - acc: 0.8250 - val_loss: 0.2128 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.4517 - acc: 0.7875 - val_loss: 0.2041 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.3545 - acc: 0.8125 - val_loss: 0.1781 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.3558 - acc: 0.8000 - val_loss: 0.1729 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2563 - acc: 0.9000 - val_loss: 0.1768 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.3044 - acc: 0.8500 - val_loss: 0.1746 - val_acc: 0.8500\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 0.2709 - acc: 0.8500 - val_loss: 0.1701 - val_acc: 0.8500\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2886 - acc: 0.8125 - val_loss: 0.1641 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2826 - acc: 0.8750 - val_loss: 0.1618 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2715 - acc: 0.8500 - val_loss: 0.1544 - val_acc: 0.8500\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2911 - acc: 0.8375 - val_loss: 0.1406 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2188 - acc: 0.8750 - val_loss: 0.1403 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 0s 6ms/step - loss: 0.2663 - acc: 0.8500 - val_loss: 0.1410 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# compile and fit the model\n",
    "model.compile('adam', 'categorical_crossentropy', ['accuracy'])\n",
    "history = model.fit(X_normalized, y_one_hot, epochs=20, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing\n",
      "20/20 [==============================] - 0s 1ms/step\n",
      "loss: 0.22960372269153595\n",
      "acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "# evaluate model against the test data\n",
    "with open('small_test_traffic.p', 'rb') as f:\n",
    "    data_test = pickle.load(f)\n",
    "\n",
    "X_test = data_test['features']\n",
    "y_test = data_test['labels']\n",
    "\n",
    "# preprocess data\n",
    "X_normalized_test = np.array(X_test / 255.0 - 0.5 )\n",
    "y_one_hot_test = label_binarizer.fit_transform(y_test)\n",
    "\n",
    "print(\"Testing\")\n",
    "\n",
    "metrics = model.evaluate(X_normalized_test, y_one_hot_test)\n",
    "for metric_i in range(len(model.metrics_names)):\n",
    "    metric_name = model.metrics_names[metric_i]\n",
    "    metric_value = metrics[metric_i]\n",
    "    print('{}: {}'.format(metric_name, metric_value))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice, accuracy was 1.0\n",
      "Good Job, accuracy was above 90%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### DON'T MODIFY ANYTHING BELOW ###\n",
    "### Be sure to run all cells above before running this cell ###\n",
    "import grader\n",
    "\n",
    "try:\n",
    "    grader.run_grader(metrics)\n",
    "except Exception as err:\n",
    "    print(str(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
